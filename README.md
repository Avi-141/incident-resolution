# incident-resolution-v1-basic-works-better?

Download Ollama
Pull required language models of your choice
Pull nomic-embeddings as the os embedding model

Embeddings will be created locally in a json file acting as a "DB"

python3 rag_ollama_basic.py



# incident-resolution-v2-streamlit-langchain

Ollama needed
Start ollama.

Chroma DB as inmemory vector DB
(Create venv) -- good pracc

pip install -r requirements.txt

streamlit run ui.py


UI running on localhost.
Index documents located in "incidents" folder
Talk to LLM Bot

